{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training BPE based Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"<UNK>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer.from_file('/workspaces/multi-tokenizer/multi_tokenizer/pretrained/english_tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ä Mead': 16495,\n",
       " 'Ä Bud': 11957,\n",
       " 'Ä hotter': 8919,\n",
       " 'Ä posed': 15320,\n",
       " 'Ä inter': 7928,\n",
       " 'Marta': 19882,\n",
       " 'eline': 10056,\n",
       " 'George': 5709,\n",
       " 'Ä poun': 14096,\n",
       " 'rey': 7511,\n",
       " 'Ä hall': 3909,\n",
       " 'Ä frosty': 18958,\n",
       " 'Ä pyram': 15947,\n",
       " 'dd': 554,\n",
       " 'Ä ships': 8719,\n",
       " 'Chuck': 12993,\n",
       " 'Ä overjoyed': 5555,\n",
       " 'Ä baaed': 14712,\n",
       " 'Ä ThatÃƒÂ¢': 7750,\n",
       " 'Ä shivers': 12969,\n",
       " 'Ä devoured': 13792,\n",
       " 'Ä muff': 3809,\n",
       " 'osquitoes': 13926,\n",
       " 'Ä paddock': 15767,\n",
       " 'Ä sympathet': 17171,\n",
       " 'ched': 696,\n",
       " 'llies': 18295,\n",
       " 'Ä hissy': 18360,\n",
       " 'Ä saltier': 19403,\n",
       " 'Ä…': 204,\n",
       " 'Ä umbrella': 3704,\n",
       " 'ature': 3131,\n",
       " 'Ä taller': 4659,\n",
       " 'Ä next': 1013,\n",
       " 'Ä Karl': 12875,\n",
       " 'Ä squirm': 12850,\n",
       " 'Ä thin': 2268,\n",
       " 'Ä squinted': 8806,\n",
       " 'Ä seated': 15216,\n",
       " 'Ä mommie': 18379,\n",
       " 'k': 85,\n",
       " 'Ã…ÄµWeÃƒÂ¢': 9079,\n",
       " 'Ä tid': 2370,\n",
       " \".'\": 5708,\n",
       " 'Ä parade': 3842,\n",
       " 'Pain': 14954,\n",
       " 'Ä Kaylee': 11899,\n",
       " 'Ä backup': 15240,\n",
       " 'Stacey': 17016,\n",
       " 'Ä apologised': 8174,\n",
       " 'Ä knee': 2286,\n",
       " 'Ä either': 3999,\n",
       " 'Ä twenty': 7289,\n",
       " 'Ä Mixing': 12729,\n",
       " 'Ä taps': 11199,\n",
       " 'Win': 17966,\n",
       " 'Ä scowl': 17420,\n",
       " 'Ä defeat': 9089,\n",
       " 'Ä fishies': 15440,\n",
       " 'Ä Whiskers': 4123,\n",
       " 'Then': 1494,\n",
       " 'ination': 2887,\n",
       " 'Ä pirate': 3238,\n",
       " 'Ä cu': 918,\n",
       " 'Ä cooperative': 14717,\n",
       " 'Ä headlight': 18884,\n",
       " 'Megan': 12380,\n",
       " 'Ä hedgehog': 6277,\n",
       " 'Ä Clarissa': 15890,\n",
       " 'Missy': 14674,\n",
       " 'Ä appreciative': 19423,\n",
       " 'Ä tune': 5629,\n",
       " 'Ä feasts': 19621,\n",
       " 'Ä makes': 1589,\n",
       " 'ergarten': 13075,\n",
       " 'Ä youngest': 9585,\n",
       " 'Ä nods': 2585,\n",
       " 'Mart': 10008,\n",
       " 'Ä choosing': 8626,\n",
       " 'Ä Someday': 16404,\n",
       " 'When': 934,\n",
       " 'Lollipop': 20137,\n",
       " 'Ä poor': 2673,\n",
       " 'Ä Pipp': 6200,\n",
       " 'Ä Quick': 7719,\n",
       " 'Jasmine': 10973,\n",
       " 'Taste': 14002,\n",
       " 'Ä smokestack': 16083,\n",
       " 'seed': 9253,\n",
       " 'Ä continuing': 11147,\n",
       " 'reliable': 18972,\n",
       " 'moving': 19189,\n",
       " 'Ä hooves': 9348,\n",
       " 'Ä Boop': 14172,\n",
       " 'Sister': 17932,\n",
       " 'Ä orange': 1952,\n",
       " 'Ä 13': 19573,\n",
       " 'Ä Musician': 19951,\n",
       " 'Ä misunder': 15676,\n",
       " 'Paula': 9108,\n",
       " 'Ä isn': 4761,\n",
       " 'Ä purpose': 8248,\n",
       " 'Excuse': 6097,\n",
       " 'Ä Those': 7252,\n",
       " 'Ä overhead': 8495,\n",
       " 'Ä wonder': 1096,\n",
       " 'Ä 5': 8868,\n",
       " 'Ä GinaÃƒÂ¢': 19720,\n",
       " 'Ä draining': 18816,\n",
       " 'raph': 12735,\n",
       " 'Â¯': 118,\n",
       " 'Ä accurate': 15973,\n",
       " 'Ä drives': 6176,\n",
       " 'Ä daughters': 13152,\n",
       " 'Ä purple': 2107,\n",
       " 'ints': 14071,\n",
       " 'loved': 16271,\n",
       " 'Ä Ryan': 7998,\n",
       " 'Casper': 16125,\n",
       " 'Ä profusely': 16956,\n",
       " 'Ä tightness': 15513,\n",
       " 'yy': 14048,\n",
       " \"'d\": 2688,\n",
       " 'Ä Caw': 18739,\n",
       " 'Biggs': 20095,\n",
       " 'Ä now': 981,\n",
       " 'Ä fittest': 20347,\n",
       " 'Will': 4927,\n",
       " 'onday': 12359,\n",
       " 'Ä Piper': 11607,\n",
       " 'Ä drops': 4230,\n",
       " 'Ä situations': 9195,\n",
       " 'Lori': 13969,\n",
       " 'Ä scanning': 19923,\n",
       " 'Ä wrong': 1435,\n",
       " 'Ä exchange': 9209,\n",
       " 'Ä impatiently': 10386,\n",
       " 'ntrigued': 13350,\n",
       " 'Rel': 13986,\n",
       " 'Ä Doesn': 17436,\n",
       " 'Ä flippers': 10315,\n",
       " 'three': 14356,\n",
       " 'Ä Stop': 5865,\n",
       " 'Ä marve': 7944,\n",
       " 'Ä leads': 7391,\n",
       " 'Ä decreased': 15926,\n",
       " 'Ä buyers': 16897,\n",
       " 'Ä Lotty': 18586,\n",
       " 'Ä pharma': 16971,\n",
       " 'olt': 19072,\n",
       " 'Ä wrinkle': 19692,\n",
       " 'Ethan': 13954,\n",
       " 'Ä uncertain': 13920,\n",
       " 'Ä tried': 744,\n",
       " 'Ä flut': 2520,\n",
       " 'zen': 5734,\n",
       " 'Patience': 17345,\n",
       " 'Ä returns': 15576,\n",
       " 'Ä Think': 12318,\n",
       " 'Ä simply': 8189,\n",
       " 'Ä chipped': 16601,\n",
       " 'Ä grandp': 6734,\n",
       " 'Ä sunscreen': 7937,\n",
       " 'Ä Reading': 11286,\n",
       " 'ux': 5733,\n",
       " 'Ä papa': 8242,\n",
       " 'iffere': 10079,\n",
       " 'Ä sat': 1393,\n",
       " 'Mic': 14940,\n",
       " 'Ä parades': 19148,\n",
       " 'Ä contest': 5758,\n",
       " 'osition': 19039,\n",
       " 'Ä captured': 15631,\n",
       " 'Ä rec': 2338,\n",
       " 'Ä Sh': 4115,\n",
       " 'lys': 12720,\n",
       " 'Ä ledge': 19356,\n",
       " 'Afterward': 15474,\n",
       " 'iques': 17604,\n",
       " 'Ä Tap': 15106,\n",
       " 'ext': 3129,\n",
       " 'Ä capes': 9744,\n",
       " 'Ä ger': 7800,\n",
       " 'lly': 867,\n",
       " 'Mosquitoes': 16184,\n",
       " 'jack': 8129,\n",
       " 'Cleaning': 17487,\n",
       " 'Ä proper': 7266,\n",
       " 'Ä Unknown': 17226,\n",
       " 'Ä declared': 8199,\n",
       " 'Ä harbor': 4590,\n",
       " 'Ä real': 980,\n",
       " 'Ä cookie': 2392,\n",
       " 'Ä normal': 3216,\n",
       " 'ippery': 4316,\n",
       " 'Ä bank': 5751,\n",
       " 'Ä gross': 6782,\n",
       " 'Those': 6738,\n",
       " 'Ä hissing': 10788,\n",
       " 'Ä unkind': 9751,\n",
       " 'Ä adventurers': 11453,\n",
       " 'Ä pass': 2328,\n",
       " 'Ä meaningful': 11636,\n",
       " 'Ä managed': 2980,\n",
       " 'Ä pluck': 12204,\n",
       " 'Ä clatter': 16544,\n",
       " 'Diamond': 17785,\n",
       " 'Ä festivities': 20009,\n",
       " 'Ä limping': 12532,\n",
       " 'Ä bookshelves': 14603,\n",
       " 'Ä pale': 3507,\n",
       " 'Ä celebrate': 3616,\n",
       " 'Ä crumbs': 6282,\n",
       " 'allist': 15195,\n",
       " 'wardrobe': 19114,\n",
       " 'Ä ha': 307,\n",
       " 'Ä comes': 2041,\n",
       " 'Ä gent': 1498,\n",
       " 'arshmallow': 6546,\n",
       " 'Ä Jean': 8946,\n",
       " 'omile': 14099,\n",
       " 'Ä Box': 17349,\n",
       " 'Ä neater': 13372,\n",
       " 'Ä buzzed': 6923,\n",
       " 'Ä slashed': 16668,\n",
       " 'Ä cat': 714,\n",
       " 'Ä tug': 4811,\n",
       " 'Ä atop': 9396,\n",
       " 'cias': 15698,\n",
       " 'Ä chin': 7813,\n",
       " 'Ä aisle': 8197,\n",
       " 'Ä travelers': 17150,\n",
       " 'Ä letÃƒÂ¢': 5880,\n",
       " 'Ä piles': 5615,\n",
       " 'Ä motionless': 17290,\n",
       " 'Ä whisp': 2647,\n",
       " 'Ä imaginary': 7826,\n",
       " 'Ä Ask': 16878,\n",
       " 'ient': 1330,\n",
       " 'Ä set': 1388,\n",
       " 'Ä stepped': 1776,\n",
       " 'Ä barked': 2466,\n",
       " 'Ä bulls': 12955,\n",
       " 'Ä baking': 4509,\n",
       " 'Ä zero': 5463,\n",
       " 'Din': 12108,\n",
       " 'Ä Winston': 13047,\n",
       " 'If': 4008,\n",
       " 'Ä museums': 15704,\n",
       " 'yers': 14050,\n",
       " 'Ä Jolene': 16070,\n",
       " 'Ä Nosy': 11536,\n",
       " 'Ä grunted': 13136,\n",
       " 'Ä unicycle': 20394,\n",
       " 'Ä wings': 1889,\n",
       " 'Ä darlings': 8376,\n",
       " 'Ä button': 2187,\n",
       " 'Ä decorated': 5706,\n",
       " 'Ä discussing': 7716,\n",
       " 'Ä guinea': 16940,\n",
       " 'Ä quick': 1077,\n",
       " 'Ä colorful': 1748,\n",
       " 'Ä scr': 2684,\n",
       " 'Ä matches': 5156,\n",
       " 'Ä wavered': 18173,\n",
       " 'Ä orchard': 9894,\n",
       " 'Ä Perhaps': 17521,\n",
       " 'Ä enters': 17001,\n",
       " 'Ä squint': 18913,\n",
       " 'Ä leftover': 13549,\n",
       " 'Ä Sale': 11763,\n",
       " 'Ä urged': 5784,\n",
       " 'ept': 6703,\n",
       " 'Ä Strawberry': 19201,\n",
       " 'Ä Zigzag': 9592,\n",
       " 'Ä puppeteer': 19558,\n",
       " 'Ä guitars': 10162,\n",
       " 'Ä Today': 3254,\n",
       " 'Ä Un': 4599,\n",
       " 'orus': 14121,\n",
       " 'onnie': 8479,\n",
       " 'Ä Suna': 13323,\n",
       " 'imi': 4618,\n",
       " 'aret': 7811,\n",
       " 'Ä cabin': 2981,\n",
       " 'Ä does': 1171,\n",
       " 'Ä stubb': 3162,\n",
       " 'Ä whatÃƒÂ¢': 8582,\n",
       " 'Zigzag': 17985,\n",
       " 'chini': 15189,\n",
       " 'onies': 7320,\n",
       " 'Ä meas': 4027,\n",
       " 'Ä Pr': 7159,\n",
       " 'Ä rem': 906,\n",
       " 'Ä sincere': 9076,\n",
       " 'agged': 11081,\n",
       " 'Ä contained': 11881,\n",
       " 'Peggy': 10215,\n",
       " 'Ä phra': 13579,\n",
       " 'Whose': 12939,\n",
       " 'Ä hippos': 10634,\n",
       " 'Ä Judy': 7040,\n",
       " 'Ä race': 1756,\n",
       " 'Ä countertops': 17653,\n",
       " 'ime': 402,\n",
       " 'Ä high': 1151,\n",
       " 'Ä Will': 4198,\n",
       " 'en': 304,\n",
       " 'ito': 4568,\n",
       " 'aya': 16383,\n",
       " 'Ä Trying': 18234,\n",
       " 'Ä squeaking': 19493,\n",
       " 'Ä mentioned': 5663,\n",
       " 'Ä airy': 18988,\n",
       " 'Ä flung': 18590,\n",
       " 'Ä mixture': 6723,\n",
       " 'imum': 18281,\n",
       " 'Ä theatre': 8375,\n",
       " 'Ä zagging': 15466,\n",
       " 'Ä comfortable': 2690,\n",
       " 'inkle': 7816,\n",
       " 'Ä splint': 14421,\n",
       " 'Ä qu': 753,\n",
       " 'Ä blanket': 1730,\n",
       " 'Ind': 13960,\n",
       " 'Ä communicated': 19665,\n",
       " 'Ä Zoey': 8172,\n",
       " 'Sammy': 4852,\n",
       " 'Ä Gwen': 16810,\n",
       " 'Ã…ÄµDonÃƒÂ¢': 5905,\n",
       " 'ody': 6032,\n",
       " 'ises': 1678,\n",
       " 'Ä sweeping': 13060,\n",
       " 'Ä Sophia': 6783,\n",
       " 'Ä planes': 4977,\n",
       " 'Ä Move': 12727,\n",
       " 'Ä aahed': 18143,\n",
       " 'Qu': 5128,\n",
       " 'Ä Jacky': 6736,\n",
       " 'Ä insistent': 11209,\n",
       " 'Ä sunf': 3020,\n",
       " 'Jessie': 8045,\n",
       " 'Ä teacherÃƒÂ¢': 16965,\n",
       " 'Ä mentioning': 17239,\n",
       " 'Ä songs': 2411,\n",
       " 'Ä infl': 19439,\n",
       " 'Ä repl': 1087,\n",
       " 'imals': 11432,\n",
       " 'bag': 14009,\n",
       " 'Ä Diamonds': 20115,\n",
       " 'Ä potty': 11910,\n",
       " 'Ä bottom': 2928,\n",
       " 'Ä beams': 13038,\n",
       " 'Ä smirking': 18438,\n",
       " 'Ä dying': 14087,\n",
       " 'Dad': 2541,\n",
       " 'Ä Eventually': 3876,\n",
       " 'Ä involved': 10708,\n",
       " 'ners': 6677,\n",
       " 'Ä sips': 11013,\n",
       " 'Ä posted': 13646,\n",
       " 'Ä holes': 3953,\n",
       " 'Ä Beartie': 15617,\n",
       " 'Ä dan': 927,\n",
       " 'Ä healthy': 2213,\n",
       " 'Ä truthful': 15682,\n",
       " 'Ä introduc': 5430,\n",
       " 'Ä Wings': 10539,\n",
       " 'Ä seeking': 12240,\n",
       " 'Ä June': 6821,\n",
       " 'al': 409,\n",
       " 'Ä tomato': 3463,\n",
       " 'Ä drooped': 16860,\n",
       " 'Ä uncle': 3484,\n",
       " 'Both': 9100,\n",
       " 'Ä shook': 1971,\n",
       " 'Ä hockey': 3978,\n",
       " 'Ä homes': 5044,\n",
       " 'Ä normally': 11545,\n",
       " 'umber': 2221,\n",
       " 'Ä mountains': 5478,\n",
       " 'Ä bug': 1459,\n",
       " 'Ä ris': 10050,\n",
       " 'orous': 16416,\n",
       " 'Lenny': 11698,\n",
       " 'Ä embra': 8635,\n",
       " 'Ã‡': 142,\n",
       " 'may': 14023,\n",
       " 'Ä mysteries': 9296,\n",
       " 'Ä network': 6396,\n",
       " 'Ä Honesty': 15962,\n",
       " 'Ä nimble': 18268,\n",
       " 'Ä Buddy': 4067,\n",
       " 'Ä ide': 990,\n",
       " 'Ä opin': 5842,\n",
       " 'Ä destro': 3509,\n",
       " 'Jon': 9103,\n",
       " 'atty': 11759,\n",
       " 'Ä curvy': 17157,\n",
       " 'Ä Lila': 1506,\n",
       " 'Ä tamb': 16322,\n",
       " 'reak': 18174,\n",
       " 'Â¤': 108,\n",
       " 'icker': 15249,\n",
       " 'ulfed': 18991,\n",
       " 'Ä small': 803,\n",
       " 'hh': 13237,\n",
       " 'bbage': 14265,\n",
       " 'Ä du': 15089,\n",
       " 'Ä chap': 14233,\n",
       " 'Chicky': 19469,\n",
       " 'iz': 796,\n",
       " 'Ä quantum': 18699,\n",
       " 'Ä jelly': 2778,\n",
       " 'Ä curtain': 3985,\n",
       " 'Move': 11699,\n",
       " 'Ä Getting': 19619,\n",
       " 'Ä purse': 3749,\n",
       " 'Ä gar': 2584,\n",
       " 'Ä zebras': 7584,\n",
       " 'Ã…ÄµWhy': 6264,\n",
       " 'Ä woodpecker': 9360,\n",
       " 'Ä chair': 1863,\n",
       " 'Ä chick': 2458,\n",
       " 'Ä canceled': 17459,\n",
       " 'cuse': 6052,\n",
       " 'Sabrina': 12593,\n",
       " 'Ä plane': 2150,\n",
       " 'Ä jingled': 13789,\n",
       " 'J': 52,\n",
       " 'Ä crispy': 10437,\n",
       " 'Ä prove': 7167,\n",
       " 'Ä dipping': 15585,\n",
       " 'Ã¬': 179,\n",
       " 'Ä savanna': 17372,\n",
       " 'Please': 2562,\n",
       " 'Ä cloud': 1655,\n",
       " 'Ãº': 193,\n",
       " 'unt': 2126,\n",
       " 'Ä shrunk': 7828,\n",
       " 'Ä products': 11652,\n",
       " 'bbies': 15322,\n",
       " 'Ä ahold': 18142,\n",
       " 'Ä their': 461,\n",
       " '\\',\"': 14896,\n",
       " 'Close': 12461,\n",
       " 'Ä solutions': 9966,\n",
       " 'Ä trotted': 7590,\n",
       " 'Cheerful': 19836,\n",
       " 'Ä slides': 3531,\n",
       " 'Ä Bloom': 11947,\n",
       " 'ka': 9829,\n",
       " 'Ä Oak': 8815,\n",
       " 'Ä dump': 8057,\n",
       " 'Ä tickly': 10896,\n",
       " '<ES>': 5,\n",
       " 'Ä curi': 1152,\n",
       " 'Ä Fairy': 9700,\n",
       " 'Ä Nadia': 13516,\n",
       " 'Ä Bee': 7425,\n",
       " 'Frankie': 10688,\n",
       " 'Ä tread': 16573,\n",
       " 'Ä disrupted': 17581,\n",
       " 'Ä inserted': 12561,\n",
       " 'Jonnie': 17843,\n",
       " 'Ä wasted': 6382,\n",
       " 'Ä eyes': 1072,\n",
       " 'omb': 8474,\n",
       " 'Ä howling': 10093,\n",
       " 'vy': 12154,\n",
       " 'Months': 13064,\n",
       " 'Ä polite': 2614,\n",
       " 'Ä ape': 12910,\n",
       " 'Ä squishing': 15461,\n",
       " 'ilight': 18245,\n",
       " 'Ä Home': 13333,\n",
       " 'Ä guidance': 11906,\n",
       " 'Ä headset': 18883,\n",
       " 'Ä Fido': 7685,\n",
       " 'Ä comparison': 19016,\n",
       " 'Ä nest': 2006,\n",
       " 'Ä Mark': 3044,\n",
       " 'Brenda': 17759,\n",
       " 'Ä bleed': 4933,\n",
       " 'boy': 14984,\n",
       " 'Ä cour': 1860,\n",
       " 'Shannon': 15753,\n",
       " 'iceLand': 16570,\n",
       " 'orried': 18287,\n",
       " 'Ä drive': 2324,\n",
       " 'Ä fountain': 3260,\n",
       " 'NG': 10733,\n",
       " 'Ä changed': 3421,\n",
       " 'Ä activities': 6186,\n",
       " 'Ä Simp': 18275,\n",
       " 'fully': 1294,\n",
       " 'ears': 7237,\n",
       " 'Ä Covering': 19489,\n",
       " 'Ä ached': 14061,\n",
       " 'Ä spite': 16522,\n",
       " 'Ä engulfed': 19353,\n",
       " 'Ä horns': 6071,\n",
       " 'Ä reply': 6441,\n",
       " 'Luna': 10470,\n",
       " 'Ä True': 4498,\n",
       " 'Ä inse': 4552,\n",
       " 'Ä grump': 9155,\n",
       " 'Milly': 6872,\n",
       " 'Ä protection': 8928,\n",
       " 'fork': 13234,\n",
       " 'uffing': 16874,\n",
       " 'ator': 2569,\n",
       " 'Alicia': 13636,\n",
       " 'Ä Marshmallow': 10300,\n",
       " 'Ä fulf': 10242,\n",
       " 'Ä Comb': 15363,\n",
       " 'Ä advertisement': 16035,\n",
       " 'imet': 11359,\n",
       " 'Ä imagines': 12904,\n",
       " 'Ä village': 2433,\n",
       " 'Ä Bess': 12710,\n",
       " 'Ä rowing': 10923,\n",
       " 'Ä compromise': 9046,\n",
       " 'Ä Debby': 12051,\n",
       " 'Ä caretaker': 10549,\n",
       " 'Ä earth': 3366,\n",
       " 'Match': 16179,\n",
       " 'Ä responsibilities': 15833,\n",
       " 'Ä rudely': 16862,\n",
       " 'gr': 9226,\n",
       " 'Ä’': 217,\n",
       " 'Ä merma': 7451,\n",
       " 'Ä backed': 6589,\n",
       " 'Ä suppose': 12915,\n",
       " 'Ä disobey': 8855,\n",
       " \",'\": 8857,\n",
       " 'llas': 8571,\n",
       " 'Ä Matilda': 9624,\n",
       " 'Ä contracts': 16011,\n",
       " 'Ä Shauna': 20053,\n",
       " '.\\'\"': 10668,\n",
       " 'Ä Sissy': 12184,\n",
       " 'pler': 14242,\n",
       " 'Ä sword': 3093,\n",
       " 'Ä caterpillar': 2914,\n",
       " 'Ä rattling': 14808,\n",
       " 'Ä require': 19487,\n",
       " 'Ä petal': 9287,\n",
       " 'Ä hopping': 2720,\n",
       " 'fume': 5084,\n",
       " 'Ä Ä Ä ÄŠ': 16320,\n",
       " 'keletons': 13674,\n",
       " 'Ã…ÄµNext': 15392,\n",
       " 'Ä marketplace': 19299,\n",
       " 'Ä notice': 3229,\n",
       " 'Ä Sunny': 5752,\n",
       " 'Ä shared': 1683,\n",
       " 'ought': 612,\n",
       " 'Ä Hurray': 18303,\n",
       " 'Ä Barry': 10061,\n",
       " 'ires': 12347,\n",
       " 'Ä outfit': 5826,\n",
       " 'Ã…ÄµWhoÃƒÂ¢': 19756,\n",
       " 'Ä couches': 14453,\n",
       " 'Ä tracks': 5359,\n",
       " 'ounced': 7437,\n",
       " 'Ä mask': 3628,\n",
       " 'Ä Lacy': 11406,\n",
       " 'iving': 10022,\n",
       " 'Ä Wilma': 13800,\n",
       " 'Ä success': 2708,\n",
       " 'Ä Success': 16407,\n",
       " 'Ä rinse': 9986,\n",
       " 'Ä spooky': 7655,\n",
       " 'Ä pu': 848,\n",
       " 'Ä blaring': 18613,\n",
       " 'S': 61,\n",
       " 'Ä searched': 2130,\n",
       " 'Ä slithery': 19701,\n",
       " 'ng': 1176,\n",
       " 'pected': 5892,\n",
       " 'Ä Daddy': 1864,\n",
       " 'rier': 7424,\n",
       " 'Ä Midnight': 10805,\n",
       " 'Ä resol': 12725,\n",
       " 'Ä werebe': 15209,\n",
       " 'flying': 17398,\n",
       " 'Ä Fixing': 18648,\n",
       " 'Ä multip': 14843,\n",
       " 'Emmy': 8933,\n",
       " 'Ä Dora': 9404,\n",
       " 'Ä written': 6043,\n",
       " 'writing': 18114,\n",
       " 'Ä answ': 1736,\n",
       " 'Ä gri': 12176,\n",
       " 'Ä hands': 1067,\n",
       " 'Ä erupt': 9439,\n",
       " 'Nadia': 14949,\n",
       " 'Ä near': 1106,\n",
       " 'Ä hurried': 5602,\n",
       " 'Tina': 6998,\n",
       " 'Ä Pandas': 15413,\n",
       " 'tocked': 16299,\n",
       " 'Ä saws': 16508,\n",
       " 'Puss': 17915,\n",
       " 'Ä grandfather': 7769,\n",
       " 'vation': 18107,\n",
       " 'Ä eyeb': 14353,\n",
       " 'Ä wax': 10034,\n",
       " 'Ä willing': 6762,\n",
       " 'Ä Cable': 11846,\n",
       " 'brown': 19085,\n",
       " 'pped': 608,\n",
       " 'Ä Soap': 16710,\n",
       " 'Ä»': 258,\n",
       " 'Ä jewels': 5125,\n",
       " 'Ä smoot': 10355,\n",
       " 'Ä perse': 12323,\n",
       " 'Ä rubbers': 19347,\n",
       " 'Ä sandbag': 18933,\n",
       " 'dvent': 11718,\n",
       " 'Ä smell': 1387,\n",
       " 'Ä intense': 15325,\n",
       " 'Ã…ÄµBe': 9157,\n",
       " 'Ä runway': 14271,\n",
       " 'Bessie': 13946,\n",
       " 'inery': 18165,\n",
       " 'ara': 657,\n",
       " 'Ä Splat': 19655,\n",
       " 'spread': 16912,\n",
       " 'Ä tagging': 17096,\n",
       " 'Ä desper': 7756,\n",
       " 'Ä despair': 12896,\n",
       " 'Ä sail': 1561,\n",
       " 'Luck': 16167,\n",
       " 'Ä sprite': 19081,\n",
       " 'Ä baby': 1514,\n",
       " 'Ä Man': 8486,\n",
       " 'Ä robber': 7309,\n",
       " 'toot': 16983,\n",
       " 'Ä You': 564,\n",
       " 'Ä goodnight': 5928,\n",
       " 'Ä airpl': 4718,\n",
       " 'oline': 6392,\n",
       " 'Ä moles': 18693,\n",
       " 'Paola': 14811,\n",
       " 'Soon': 2387,\n",
       " 'Ä dandel': 11021,\n",
       " 'Ä mailing': 11502,\n",
       " 'Ä Janelle': 13722,\n",
       " 'Ä There': 1501,\n",
       " 'Ä generous': 2702,\n",
       " 'Ä refle': 6770,\n",
       " 'Ä lounging': 17677,\n",
       " 'Ä beings': 16443,\n",
       " 'ches': 1948,\n",
       " 'Ä pulled': 1660,\n",
       " 'Ä flew': 944,\n",
       " 'Ä chasing': 3615,\n",
       " 'Emily': 5387,\n",
       " 'Ä venture': 9194,\n",
       " 'plash': 10085,\n",
       " 'Ä Firefighters': 16090,\n",
       " 'Ä sets': 8423,\n",
       " 'Ä remained': 5161,\n",
       " 'Ä brilli': 2922,\n",
       " 'Ä lemonade': 4523,\n",
       " 'Ä smoothest': 14764,\n",
       " 'Ä release': 5984,\n",
       " 'Ä twirling': 5782,\n",
       " 'Do': 1995,\n",
       " 'Catch': 12107,\n",
       " 'Mummy': 3002,\n",
       " 'Ä clogged': 14276,\n",
       " 'Ä Elephant': 10082,\n",
       " 'Ä soups': 15559,\n",
       " 'Ä Lee': 4376,\n",
       " 'Ä neck': 1898,\n",
       " 'Ä beginnings': 15771,\n",
       " 'Ä enjoying': 3104,\n",
       " 'Ä frees': 17099,\n",
       " 'Grandad': 15912,\n",
       " 'Ä someday': 4972,\n",
       " 'Ä Wanda': 16568,\n",
       " 'Ä ut': 16318,\n",
       " 'Ä talk': 1571,\n",
       " 'Ä angle': 13625,\n",
       " 'chirp': 18401,\n",
       " 'Ä lure': 18187,\n",
       " 'op': 509,\n",
       " 'Ä agre': 1477,\n",
       " 'Ä smoking': 8925,\n",
       " 'Joan': 15469,\n",
       " 'anation': 11765,\n",
       " 'Ä susie': 18144,\n",
       " 'Ä mooed': 10429,\n",
       " 'osity': 5113,\n",
       " 'Ä daisy': 5094,\n",
       " 'Ä bean': 3456,\n",
       " 'Ä pra': 4569,\n",
       " 'Ä bleeding': 5470,\n",
       " 'Ä contented': 9938,\n",
       " 'Ä dumped': 10947,\n",
       " 'ige': 9391,\n",
       " 'Ä completed': 5679,\n",
       " 'Ä brushed': 5498,\n",
       " 'Ä Karla': 11487,\n",
       " 'Ä fairy': 1850,\n",
       " 'utt': 10512,\n",
       " 'ary': 996,\n",
       " 'Ä smoky': 11166,\n",
       " 'Ä Baa': 7873,\n",
       " 'Ä Island': 11594,\n",
       " 'Ä radi': 14510,\n",
       " 'Ä gutter': 18249,\n",
       " 'Ä traders': 13826,\n",
       " 'Ä mantelpiece': 20373,\n",
       " 'Meeting': 20011,\n",
       " 'Ä snooty': 20384,\n",
       " 'Ä striking': 9184,\n",
       " 'Hank': 11696,\n",
       " 'Ä ent': 2203,\n",
       " 'Ä exhib': 9532,\n",
       " 'Ä stormed': 14342,\n",
       " 'gain': 7859,\n",
       " 'iled': 6583,\n",
       " 'Ä flowing': 8588,\n",
       " 'Ä rearr': 14185,\n",
       " 'Ä ruins': 15481,\n",
       " 'Ä stairways': 17288,\n",
       " 'Ä rect': 13375,\n",
       " 'Ä Thenry': 16738,\n",
       " 'iko': 11232,\n",
       " 'Ä unatt': 15422,\n",
       " 'Ä searching': 3308,\n",
       " 'Ä willingness': 17323,\n",
       " 'Ä nanny': 9243,\n",
       " 'Ä aff': 6379,\n",
       " 'fuse': 18471,\n",
       " 'Ä patchy': 19354,\n",
       " 'Ä shower': 4532,\n",
       " 'orial': 19730,\n",
       " 'Ä pride': 4967,\n",
       " 'Ä pinecone': 17588,\n",
       " 'Ä wisely': 7765,\n",
       " 'sama': 13258,\n",
       " 'Ä Pl': 6289,\n",
       " 'Ä Tent': 18231,\n",
       " 'Ä shrugging': 15584,\n",
       " 'aying': 7037,\n",
       " 'Ä Phil': 9909,\n",
       " 'Ä cabinet': 4364,\n",
       " 'Ä Rory': 11130,\n",
       " 'Ä Syl': 16406,\n",
       " 'Ä \"': 344,\n",
       " 'Ä Jess': 4593,\n",
       " 'Ä fascin': 5200,\n",
       " 'Ä Kiki': 9167,\n",
       " 'Ä Teacher': 15870,\n",
       " 'Ä napping': 7420,\n",
       " 'Ä Rest': 16840,\n",
       " 'an': 310,\n",
       " 'Ä ponytails': 19979,\n",
       " 'Ä anticipation': 7500,\n",
       " 'Ä staircase': 12017,\n",
       " 'Ä cleaner': 7689,\n",
       " 'Ä fellow': 15251,\n",
       " 'Ä forces': 14163,\n",
       " 'bum': 14983,\n",
       " 'Ä Trudy': 15695,\n",
       " 'Ä dangerous': 1775,\n",
       " 'Ä toothache': 19327,\n",
       " 'Ä transplant': 19722,\n",
       " 'Ä Finders': 13807,\n",
       " 'Ä ankles': 19728,\n",
       " 'Chom': 14584,\n",
       " 'Basil': 14906,\n",
       " 'Ä privacy': 13081,\n",
       " 'Ä maze': 4307,\n",
       " 'ms': 7660,\n",
       " 'Ä patching': 19047,\n",
       " 'Ä accident': 1814,\n",
       " 'Ä potions': 12351,\n",
       " 'Ä happ': 385,\n",
       " 'Ä disappear': 4575,\n",
       " 'Ä pole': 4300,\n",
       " 'Ä harvested': 13078,\n",
       " 'gs': 4185,\n",
       " 'Ä captain': 4892,\n",
       " 'omes': 4822,\n",
       " 'Ä ill': 8385,\n",
       " 'Ä tire': 3757,\n",
       " 'Zane': 14980,\n",
       " 'Ä sharpen': 13586,\n",
       " 'Despite': 11296,\n",
       " 'airy': 7891,\n",
       " 'Ä drips': 13540,\n",
       " 'Ä dared': 6347,\n",
       " 'Ä unzipped': 13846,\n",
       " 'Ä snows': 15507,\n",
       " 'uck': 621,\n",
       " 'Ä quokka': 16066,\n",
       " 'Ä droplets': 17652,\n",
       " 'Ä dealing': 19614,\n",
       " 'Ä much': 723,\n",
       " 'Ä intric': 15324,\n",
       " 'Ä bristles': 12553,\n",
       " 'Ä sparrows': 17466,\n",
       " 'Ä flamingos': 20019,\n",
       " 'Ä ignores': 11518,\n",
       " 'Ä stead': 10874,\n",
       " 'arkable': 12236,\n",
       " 'Ä Bonnie': 9521,\n",
       " 'Animals': 19625,\n",
       " 'Molly': 2359,\n",
       " 'ivity': 6718,\n",
       " ']': 71,\n",
       " 'Ä bakery': 6487,\n",
       " 'Ä Ollie': 5780,\n",
       " 'Ã…ÄµThen': 18765,\n",
       " 'Wait': 4767,\n",
       " 'Ä sunsh': 18689,\n",
       " 'ond': 2180,\n",
       " 'elly': 2547,\n",
       " 'Ä rins': 16441,\n",
       " 'Ä scrape': 11229,\n",
       " 'dest': 13229,\n",
       " 'een': 2263,\n",
       " 'Ä desert': 6269,\n",
       " 'Ä dra': 965,\n",
       " 'Everybody': 10885,\n",
       " 'Ä Heidi': 11040,\n",
       " 'ees': 16257,\n",
       " 'Ä chubby': 4191,\n",
       " 'Ä unt': 813,\n",
       " 'oose': 2314,\n",
       " 'Ä wrapped': 2993,\n",
       " 'Ä squealed': 6281,\n",
       " 'ye': 3210,\n",
       " 'Ä poisonous': 8941,\n",
       " 'Ama': 16099,\n",
       " 'May': 7069,\n",
       " 'Ä dumb': 9240,\n",
       " 'Ä coughed': 9095,\n",
       " 'Ä howled': 10836,\n",
       " 'Äƒ': 202,\n",
       " 'Ä walks': 2867,\n",
       " 'Ä marriage': 5954,\n",
       " 'Kate': 6844,\n",
       " 'Ä memb': 7613,\n",
       " 'Ä chilly': 7814,\n",
       " 'Ä raking': 10109,\n",
       " 'Ä squeaky': 8534,\n",
       " 'Ä sicker': 11168,\n",
       " 'Ä uniformed': 15734,\n",
       " 'Ä Pogo': 18830,\n",
       " 'Ä Valley': 19538,\n",
       " 'Ä ladle': 17019,\n",
       " 'amiliar': 9007,\n",
       " 'Swans': 19969,\n",
       " 'Not': 5424,\n",
       " 'Ä slows': 13548,\n",
       " 'Ä happy': 412,\n",
       " 'net': 13248,\n",
       " 'Ä grandma': 1483,\n",
       " 'Ä pant': 3365,\n",
       " 'Ä burger': 8107,\n",
       " 'Ã…ÄµThe': 8156,\n",
       " 'Ä Dependable': 13156,\n",
       " 'Ä Rice': 15452,\n",
       " 'Ä flavors': 7308,\n",
       " 'Ä pist': 5142,\n",
       " 'Ä Sur': 16402,\n",
       " 'Ä liz': 3199,\n",
       " 'ornn': 11766,\n",
       " 'arently': 17573,\n",
       " 'Ä aim': 7318,\n",
       " 'get': 535,\n",
       " 'Ä freezing': 8108,\n",
       " 'Ä tweeted': 15830,\n",
       " 'ceptor': 12379,\n",
       " 'Ä happens': 4664,\n",
       " 'Ä lonely': 1872,\n",
       " 'Ä Sandy': 3840,\n",
       " 'ader': 16458,\n",
       " 'fish': 2123,\n",
       " 'Ä SusieÃƒÂ¢': 17115,\n",
       " 'cream': 3880,\n",
       " 'Ä oneÃƒÂ¢': 16628,\n",
       " 'Ä cheating': 10563,\n",
       " 'Gaby': 14924,\n",
       " 'Ä Tweet': 2093,\n",
       " 'chair': 4313,\n",
       " 'lpful': 16535,\n",
       " 'Ä ripe': 5982,\n",
       " 'Ä perk': 16863,\n",
       " 'Ä iceberg': 16900,\n",
       " 'Ä playful': 3515,\n",
       " 'Ä professor': 14442,\n",
       " 'Ä avo': 3391,\n",
       " 'Ä repeats': 8190,\n",
       " 'ories': 4371,\n",
       " 'Ä works': 5162,\n",
       " 'Ä Flora': 8245,\n",
       " 'Freddie': 13027,\n",
       " 'Ä fabulous': 16060,\n",
       " 'Ä balcony': 12928,\n",
       " 'aunted': 20251,\n",
       " 'uits': 11892,\n",
       " 'Ä footprint': 13073,\n",
       " 'Ä clock': 3747,\n",
       " 'Pandy': 17899,\n",
       " 'Ä Mica': 18429,\n",
       " 'Ä looking': 1053,\n",
       " 'Ä crown': 2862,\n",
       " 'Ä Hoot': 6814,\n",
       " 'Ä mound': 12171,\n",
       " 'Ä ech': 6351,\n",
       " 'Five': 12580,\n",
       " 'Ä el': 1478,\n",
       " 'Ä remember': 1062,\n",
       " 'strid': 13044,\n",
       " 'Ä chances': 10545,\n",
       " 'uddenly': 725,\n",
       " 'Ä latest': 14865,\n",
       " 'Ä everywhere': 1711,\n",
       " 'Ä treats': 2499,\n",
       " 'squito': 4731,\n",
       " 'Ä gear': 5019,\n",
       " 'Ä complain': 4632,\n",
       " 'Ä bulbs': 9447,\n",
       " 'Ä produc': 9477,\n",
       " 'Ä triangle': 4104,\n",
       " 'Ä laughter': 4843,\n",
       " 'Å': 264,\n",
       " 'olin': 4184,\n",
       " 'Ä Im': 7870,\n",
       " 'Ä Bernie': 13132,\n",
       " 'Ä talons': 14369,\n",
       " 'Ã™': 160,\n",
       " 'Ä player': 4304,\n",
       " 'cage': 5533,\n",
       " 'ship': 9040,\n",
       " 'ention': 3152,\n",
       " 'Ä somewhat': 18526,\n",
       " 'Ä snore': 14289,\n",
       " 'Ä Kin': 13558,\n",
       " 'Ä shoppers': 16896,\n",
       " 'ety': 4760,\n",
       " 'Ä posts': 10164,\n",
       " 'Ä hourglass': 14661,\n",
       " 'ushes': 9542,\n",
       " 'Ä Sensing': 18279,\n",
       " 'Ã¶': 189,\n",
       " 'Ä wandering': 6319,\n",
       " 'Jennie': 14601,\n",
       " 'Ä Cora': 10104,\n",
       " 'Ä pocket': 1880,\n",
       " 'Ä petting': 8333,\n",
       " 'Ä cheap': 3370,\n",
       " 'angle': 8922,\n",
       " 'Ä splas': 2347,\n",
       " 'Naught': 16188,\n",
       " 'Ä dozed': 9522,\n",
       " 'Ä firework': 4352,\n",
       " 'ripe': 11774,\n",
       " 'Ä Bird': 6147,\n",
       " 'Ä¡': 232,\n",
       " 'Ã¯': 182,\n",
       " 'aids': 10165,\n",
       " 'Ä model': 5406,\n",
       " 'Ä ext': 2956,\n",
       " 'Ä restaurant': 3677,\n",
       " 'Ä needles': 6358,\n",
       " 'Ä Welcome': 7934,\n",
       " 'Ä sledding': 12787,\n",
       " 'Ä tri': 1261,\n",
       " 'x': 98,\n",
       " 'Ä Nicole': 18894,\n",
       " 'Ä great': 1084,\n",
       " 'Ä beans': 4861,\n",
       " 'ellie': 9143,\n",
       " 'gu': 3790,\n",
       " 'Ä giggles': 8164,\n",
       " 'Ä miner': 4873,\n",
       " 'Ä toilet': 4148,\n",
       " 'Ä volcanoes': 9952,\n",
       " 'toed': 11926,\n",
       " 'Ä hun': 1455,\n",
       " 'Ä sleds': 8903,\n",
       " 'Ä Bob': 1131,\n",
       " 'Ä hurry': 3807,\n",
       " 'Ä advent': 978,\n",
       " 'Ä swollen': 7573,\n",
       " 'Ä burying': 7957,\n",
       " 'Ä casting': 14411,\n",
       " 'Ä eyeing': 15639,\n",
       " 'Ä broken': 1492,\n",
       " 'artha': 7053,\n",
       " 'Ã ': 167,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.trainers import BpeTrainer\n",
    "trainer = BpeTrainer(special_tokens=[\"<UNK>\", \"<CLS>\", \"<SEP>\", \"<PAD>\", \"<MASK>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.pre_tokenizers import Whitespace, ByteLevel, BertPreTokenizer, Metaspace\n",
    "from tokenizers.processors import TemplateProcessing, BertProcessing\n",
    "# tokenizer.pre_tokenizer = Whitespace()\n",
    "# tokenizer.pre_tokenizer = ByteLevel()\n",
    "# tokenizer.pre_tokenizer = BertPreTokenizer()\n",
    "tokenizer.pre_tokenizer = Metaspace(replacement=\" \", prepend_scheme=\"never\")\n",
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"<CLS> $A:1 <SEP>:1\",\n",
    "    pair=\"<CLS> $A:1 <SEP> $B:1 <SEP>\",\n",
    "    special_tokens=[(\"<CLS>\", 1), (\"<SEP>\", 2)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello,', (0, 6)),\n",
       " (\" y'all!\", (6, 13)),\n",
       " (' How', (13, 17)),\n",
       " (' are', (17, 21)),\n",
       " (' you', (21, 25)),\n",
       " (' ğŸ˜', (25, 27)),\n",
       " (' ?', (27, 29))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(\"Hello, y'all! How are you ğŸ˜ ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"wikitext\", name=\"wikitext-2-raw-v1\", split=\"train\")\n",
    "batch_size = 1000\n",
    "all_texts = [dataset[i : i + batch_size][\"text\"] for i in range(0, len(dataset), batch_size)]\n",
    "\n",
    "def batch_iterator():\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        yield dataset[i : i + batch_size][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.train_from_iterator(batch_iterator(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.save(\"tokenizer-wiki.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = Tokenizer.from_file(\"tokenizer-wiki.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer.encode(\"Hello, y'all! How are you ğŸ˜?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<CLS>', 'H', 'ello', ',', ' y', \"'\", 'all', '!', ' How', ' are', ' you', ' ', '<UNK>', '?', '<SEP>']\n"
     ]
    }
   ],
   "source": [
    "print(output.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 46, 15853, 18, 1230, 13, 1191, 7, 4081, 1215, 2403, 6, 0, 37, 2]\n"
     ]
    }
   ],
   "source": [
    "print(output.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"H ello ,  y ' all !  How  are  you   ?\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Pretrained Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wikitext\", name=\"wikitext-2-raw-v1\", split=\"train\")\n",
    "batch_size = 1000\n",
    "all_texts = [dataset[i : i + batch_size][\"text\"] for i in range(0, len(dataset), batch_size)]\n",
    "def batch_iterator():\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        yield dataset[i : i + batch_size][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad31d74797cd49018d0cc3532143abc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d071bbb02da401c8975b1423bbd2e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/17.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17412834d1e14d0aabeaa0422ce6d15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/16.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"CohereForAI/aya-23-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer = tokenizer.train_new_from_iterator(batch_iterator(), vocab_size=25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<BOS_TOKEN>Hello, y'all! How are you ğŸ˜?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"Hello, y'all! How are you ğŸ˜?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<BOS_TOKEN>Hello, y'all! How are you ï¿½ï¿½ï¿½?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.decode(new_tokenizer.encode(\"Hello, y'all! How are you ğŸ˜?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CohereTokenizerFast(name_or_path='CohereForAI/aya-23-8B', vocab_size=25000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<BOS_TOKEN>', 'eos_token': '<|END_OF_TURN_TOKEN|>', 'pad_token': '<PAD>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<PAD>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<UNK>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<CLS>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<SEP>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"<MASK_TOKEN>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t5: AddedToken(\"<BOS_TOKEN>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t6: AddedToken(\"<EOS_TOKEN>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t7: AddedToken(\"<EOP_TOKEN>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t8: AddedToken(\"<|END_OF_TURN_TOKEN|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.cohere.tokenization_cohere_fast.CohereTokenizerFast"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ByteLevelBPE Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfcc8ca2be446aaaac35af056a51773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/733k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdeaa57dc0074668b166ff9655b29854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/157M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwikitext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwikitext-103-raw-v1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      5\u001b[0m all_texts \u001b[38;5;241m=\u001b[39m [dataset[i : i \u001b[38;5;241m+\u001b[39m batch_size][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataset), batch_size)]\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/datasets/load.py:2616\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\u001b[38;5;241m.\u001b[39mas_streaming_dataset(split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[1;32m   2615\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 2616\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2622\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2625\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2626\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   2627\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/datasets/builder.py:1029\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1028\u001b[0m         prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[0;32m-> 1029\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/datasets/builder.py:1102\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m split_dict \u001b[38;5;241m=\u001b[39m SplitDict(dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name)\n\u001b[1;32m   1101\u001b[0m split_generators_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m-> 1102\u001b[0m split_generators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msplit_generators_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;66;03m# Checksums verification\u001b[39;00m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS \u001b[38;5;129;01mand\u001b[39;00m dl_manager\u001b[38;5;241m.\u001b[39mrecord_checksums:\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/datasets/packaged_modules/parquet/parquet.py:47\u001b[0m, in \u001b[0;36mParquet._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one data file must be specified, but got data_files=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m dl_manager\u001b[38;5;241m.\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mextract_on_the_fly \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m data_files \u001b[38;5;241m=\u001b[39m \u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m splits \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split_name, files \u001b[38;5;129;01min\u001b[39;00m data_files\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/datasets/download/download_manager.py:434\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_and_extract\u001b[39m(\u001b[38;5;28mself\u001b[39m, url_or_urls):\n\u001b[1;32m    419\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download and extract given `url_or_urls`.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m    Is roughly equivalent to:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m        extracted_path(s): `str`, extracted paths of given URL(s).\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/datasets/download/download_manager.py:257\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    255\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m stack_multiprocessing_download_progress_bars():\n\u001b[0;32m--> 257\u001b[0m     downloaded_path_or_paths \u001b[38;5;241m=\u001b[39m \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDownloading data files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m duration \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    267\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;241m.\u001b[39mtotal_seconds()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/datasets/utils/py_utils.py:512\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    509\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_proc \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m%\u001b[39m num_proc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    510\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[1;32m    511\u001b[0m mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 512\u001b[0m     \u001b[43m_single_map_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m hf_tqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    514\u001b[0m ]\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[1;32m    516\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m mapped_batch \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m mapped_batch]\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/datasets/utils/py_utils.py:399\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    396\u001b[0m         k: _single_map_nested((function, v, batched, batch_size, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m pbar\n\u001b[1;32m    397\u001b[0m     }\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [\u001b[43m_single_map_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m pbar]\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mapped\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/datasets/utils/py_utils.py:380\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    375\u001b[0m     batched\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types)\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mdict\u001b[39m, types)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data_struct)\n\u001b[1;32m    379\u001b[0m ):\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mget_verbosity() \u001b[38;5;241m<\u001b[39m logging\u001b[38;5;241m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/datasets/download/download_manager.py:314\u001b[0m, in \u001b[0;36mDownloadManager._download_batched\u001b[0;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    301\u001b[0m         download_func,\n\u001b[1;32m    302\u001b[0m         url_or_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m         tqdm_class\u001b[38;5;241m=\u001b[39mtqdm,\n\u001b[1;32m    311\u001b[0m     )\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 314\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m url_or_filename \u001b[38;5;129;01min\u001b[39;00m url_or_filenames\n\u001b[1;32m    316\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/datasets/download/download_manager.py:323\u001b[0m, in \u001b[0;36mDownloadManager._download_single\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;66;03m# append the relative path to the base_path\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     url_or_filename \u001b[38;5;241m=\u001b[39m url_or_path_join(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_path, url_or_filename)\n\u001b[0;32m--> 323\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m out \u001b[38;5;241m=\u001b[39m tracked_str(out)\n\u001b[1;32m    325\u001b[0m out\u001b[38;5;241m.\u001b[39mset_origin(url_or_filename)\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/datasets/utils/file_utils.py:201\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     url_or_filename \u001b[38;5;241m=\u001b[39m strip_protocol(url_or_filename)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_etag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_etag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_url_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_url_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_desc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_desc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/datasets/utils/file_utils.py:676\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, use_auth_token, ignore_url_params, storage_options, download_desc, disable_tqdm)\u001b[0m\n\u001b[1;32m    674\u001b[0m     ftp_get(url, temp_file)\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m scheme \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 676\u001b[0m     \u001b[43mfsspec_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_desc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_tqdm\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    680\u001b[0m     http_get(\n\u001b[1;32m    681\u001b[0m         url,\n\u001b[1;32m    682\u001b[0m         temp_file\u001b[38;5;241m=\u001b[39mtemp_file,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m         disable_tqdm\u001b[38;5;241m=\u001b[39mdisable_tqdm,\n\u001b[1;32m    690\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/datasets/utils/file_utils.py:385\u001b[0m, in \u001b[0;36mfsspec_get\u001b[0;34m(url, temp_file, storage_options, desc, disable_tqdm)\u001b[0m\n\u001b[1;32m    372\u001b[0m fs, path \u001b[38;5;241m=\u001b[39m url_to_fs(url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(storage_options \u001b[38;5;129;01mor\u001b[39;00m {}))\n\u001b[1;32m    373\u001b[0m callback \u001b[38;5;241m=\u001b[39m TqdmCallback(\n\u001b[1;32m    374\u001b[0m     tqdm_kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdesc\u001b[39m\u001b[38;5;124m\"\u001b[39m: desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    383\u001b[0m     }\n\u001b[1;32m    384\u001b[0m )\n\u001b[0;32m--> 385\u001b[0m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:648\u001b[0m, in \u001b[0;36mHfFileSystem.get_file\u001b[0;34m(self, rpath, lpath, callback, outfile, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m callback\u001b[38;5;241m.\u001b[39mset_size(expected_size)\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 648\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_hub_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolve_remote_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolve_remote_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolve_remote_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_in_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolve_remote_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m            \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_hf_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_tqdm_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtqdm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTqdmCallback\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m     outfile\u001b[38;5;241m.\u001b[39mseek(initial_pos)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;66;03m# Close file only if we opened it ourselves\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/huggingface_hub/file_download.py:549\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    547\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 549\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDOWNLOAD_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[1;32m    551\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/urllib3/response.py:1060\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1060\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1063\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/urllib3/response.py:949\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 949\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/urllib3/response.py:873\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    870\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 873\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    883\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/site-packages/urllib3/response.py:856\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/envs/multi-tokenizer/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\" ,split=\"train\")\n",
    "batch_size = 1000\n",
    "all_texts = [dataset[i : i + batch_size][\"text\"] for i in range(0, len(dataset), batch_size)]\n",
    "def batch_iterator():\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        yield dataset[i : i + batch_size][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.train_from_iterator(batch_iterator(), vocab_size=25000, min_frequency=2, special_tokens=[\"<UNK>\", \"<CLS>\", \"<SEP>\", \"<PAD>\", \"<MASK>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer.encode(\"Hello, y'all! How are you ğŸ˜?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, y'all! How are you ğŸ˜?\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output.ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', (0, 5)),\n",
       " (',', (5, 6)),\n",
       " ('Ä y', (6, 8)),\n",
       " (\"'\", (8, 9)),\n",
       " ('all', (9, 12)),\n",
       " ('!', (12, 13)),\n",
       " ('Ä How', (13, 17)),\n",
       " ('Ä are', (17, 21)),\n",
       " ('Ä you', (21, 25)),\n",
       " ('Ä Ã°ÅÄºÄ£?', (25, 28))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(\"Hello, y'all! How are you ğŸ˜?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vogns', 17925),\n",
       " ('Ä 272', 24025),\n",
       " ('omes', 2346),\n",
       " ('Ä punishment', 9756),\n",
       " ('Ä Tric', 21199),\n",
       " ('Ä Relief', 21856),\n",
       " ('Ä Trotternish', 23346),\n",
       " ('enant', 4555),\n",
       " ('Ä absor', 6931),\n",
       " ('adm', 3761)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.get_vocab().items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"bytelevelbpe-tokenizer-wiki.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-tokenizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
